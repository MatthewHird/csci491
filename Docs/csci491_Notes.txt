# Notes/Comments While Coding

## Nov 17, 2019

CSharpLexer.g4 and CSharpParser.g4 assume the target language is Java (rather 
than Python3) so they manually embed some Java code (import statements, declare 
Stack<Integer> variable to count curly bracket level, increment counters/push
and pop items from stacks, etc) into the generated files (MyLexer.py and 
MyParser.py)
    - I was forced to manually convert embedded to python3
    - Good example for me to see how aditional code can manually be embedded 
    into the lexer
    - The ANTLR tutorial I followed embedded code to use an ANTLR specific 
    feature called semantic predicates (that I should look into more later).

Fixed an import issue in the ANTLR python3 file generation process
    - The class in the standard libary 'TextIO' moved from the module 
    'typing.io' to the module 'typing' between Python 3.5 and Python 3.6, but 
    the python3 template in ANTLR hadn't been updated to reflect that, so all
    python files generated by ANTLR generate an error and won't run.
    - Manual fix:
        - Extract antlr JAR (/usr/local/lib/antlr-4.7.2-complete.jar)
        - In the extracted directory open the file
        /org/antlr/v4/tool/templates/codegen/Python3/Python3.stg
            - Under 'ParserFile' and 'LexerFile' sections change
            "from typing.io import TextIO" to "from typing import TextIO"
            (lines 54 and 753)
        - Compress the directory 'org/' as a .jar
        - Move the jar to '/usr/local/lib/' and rename it to 
        antlr-4.7.2-complete.jar (replacing the old one)

CSharp files for some reason have a non-breaking space (\uFEFF) at the start of
the file
    - Probably a Byte Order Mark being misinterpretted
    - Had issue with the implementer of the CSharp grammar using a token name 
    ("LT") that was the same as method used by a number of classes in ANTLR  .
    - File had a byte order mark (or byte order mark was being read as) 
    UTF-16 (BE) even though the file was encoded as UTF-8
        - CSharp specifications only accept UTF-8 
        - Changed BYTE_ORDER_MARK in CSharpLexer from
            BYTE_ORDER_MARK: '\u00EF\u00BB\u00BF';
        to
            BYTE_ORDER_MARK: ('\u00EF\u00BB\u00BF' | '\uFEFF');


## Dec 03, 2019

### The Definitive ANTLR 4 Reference

pg 39 (55)

Before we get to the visitor, we need to make a few modifications to the
grammar. First, we need to label the alternatives of the rules. (The labels can
be any identifier that doesn’t collide with a rule name.) Without labels on the
alternatives, ANTLR generates only one visitor method per rule. (Chapter 7,
Decoupling Grammars from Application-Specific Code, on page 109 uses a similar
grammar to explain the visitor mechanism in more detail.) In our case, we’d
like a different visitor method for each alternative so that we can get different
“events” for each kind of input phrase. Labels appear on the right edge of
alternatives and start with the # symbol in our new grammar, LabeledExpr.

e.g.

stat:   expr NEWLINE                # printExpr
    |   ID '=' expr NEWLINE         # assign
    |   NEWLINE                     # blank
    ;


Listeners and visitors are great because they keep application-specific code
out of grammars, making grammars easier to read and preventing them from
getting entangled with a particular application. For the ultimate flexibility
and control, however, we can directly embed code snippets (actions) within
grammars. These actions are copied into the recursive-descent parser code
ANTLR generates. In this section, we’ll implement a simple program that reads
in rows of data and prints out the values found in a specific column. After
that, we’ll see how to make special actions, called semantic predicates,
dynamically turn parts of a grammar on and off.


pg 49 (65)

The key in the following Data grammar is a special Boolean-valued action
called a semantic predicate: {$i<=$n}?. That predicate evaluates to true until
we surpass the number of integers requested by the sequence rule parameter
n. False predicates make the associated alternative “disappear” from the
grammar and, hence, from the generated parser. In this case, a false predicate
makes the (...)* loop terminate and return from rule sequence.



pg 50 (66)

Lexical Modes

All the sample input files we’ve seen so far contain a single language, but
there are common file formats that contain multiple languages. For example,
the @author tags and so on inside Java document comments follow a mini
language; everything outside the comment is Java code. Template engines
such as StringTemplate3 and Django4 have a similar problem. They have to
treat all of the text surrounding the template expressions differently. These
are often called island grammars.

ANTLR provides a well-known lexer feature called lexical modes that lets us
deal easily with files containing mixed formats. The basic idea is to have the
lexer switch back and forth between modes when it sees special sentinel
character sequences.

XML is a good example. An XML parser treats everything other than tags and
entity references (such as &pound;) as text chunks. When the lexer sees <, it
switches to “inside” mode and switches back to the default mode when it sees
> or />. The following grammar demonstrates how this works. We’ll explore
this in more detail in Chapter 12, Wielding Lexical Black Magic, on page 203.

e.g.

open    :   '<'         -> pushMode(INSIDE) ;
TEXT    : ~('<'|'&')+ ; // match any 16 bit char minus < and &

mode INSIDE;

CLOSE   :   '>'         -> popMode();


pg 52 (68)

Our main program looks exactly the same as the one in ExtractInterfaceTool.java
from Section 4.3, Building a Translator with a Listener, on page 42 except that
we print the token stream out when the listener has finished (highlighted
with an arrow).

### tour/InsertSerialID.java

    ParseTreeWalker walker = new ParseTreeWalker(); // create standard walker
    InsertSerialIDListener extractor = new InsertSerialIDListener(tokens);
    walker.walk(extractor, tree); // initiate walk of tree with listener
    // print back ALTERED stream
➤   System.out.println(extractor.rewriter.getText());


import org.antlr.v4.runtime.TokenStream;
import org.antlr.v4.runtime.TokenStreamRewriter;
public class InsertSerialIDListener extends JavaBaseListener {
    TokenStreamRewriter rewriter;
    public InsertSerialIDListener(TokenStream tokens) {
        rewriter = new TokenStreamRewriter(tokens);
    }

    @Override
    public void enterClassBody(JavaParser.ClassBodyContext ctx) {
        String field = "\n\tpublic static final long serialVersionUID = 1L;";
        rewriter.insertAfter(ctx.start, field);
    }
}


pg 53 (69)

Channels

Traditionally, this has been a nasty requirement to fulfill. For most grammars,
comments and whitespace are things the parser can ignore. If we don’t want
to explicitly allow whitespace and comments all over the place in a grammar,
we need the lexer to throw them out. Unfortunately, that means the whitespace 
and comments are inaccessible to application code and any subsequent pro-
cessing steps. The secret to preserving but ignoring comments and whitespace
is to send those tokens to the parser on a “hidden channel.” The parser tunes
to only a single channel and so we can pass anything we want on the other
channels. Here’s how the Java grammar does it:

COMMENT 
    : '/*' .*? '*/' -> channel(HIDDEN) // match anything between /* and */
    ;
WS  :   [ \r\t\u000C\n]+ -> channel(HIDDEN)
    ;

The -> channel(HIDDEN) is a lexer command like the -> skip we discussed before.
In this case, it sets the channel number of these tokens so that it’s ignored
by the parser. The token stream still maintains the original sequence of tokens
but skips over the off-channel tokens when feeding the parser.


For future reference, here’s a table summarizing ANTLR’s core grammar
notation:
Syntax                  Description

x                       Match token, rule reference, or subrule x .
x y ... z               Match a sequence of rule elements.
(... | ... | ...)       Subrule with multiple alternatives.
x ?                     Match x or skip it.
x *                     Match x zero or more times.
x +                     Match x one or more times.
r : ... ;               Define rule r.
r : ... | ... | ... ;   Define rule r with multiple alternatives.


pg 205 (218)

To transmit tokens on a different channel, we use lexer command channel(...)
in the appropriate lexer rule. Let’s demonstrate this technique by altering our
Cymbol grammar to put comments on hidden channel 2 and whitespace on
hidden channel 1, like the last image.

@lexer::members {
    public static final int WHITESPACE = 1;
    public static final int COMMENTS = 2;
}

WS  :   [ \t\n\r]+ -> channel(WHITESPACE) ; // channel(1)
SL_COMMENT
    :   '//' .*? '\n' -> channel(COMMENTS)  // channel(2)
    ;

ANTLR translates channel(HIDDEN) to Java as _channel = HIDDEN, which sets class
Lexer’s _channel field to constant HIDDEN. We can use any valid Java qualified
identifier as an argument to command channel().
Testing the grammar with grun shows that the comments appear on channel
2, whitespace appears on channel 1, and the other tokens appear on the
default channel.


pg 207 (220)

### lexmagic/ShiftVarComments.java

public static class CommentShifter extends CymbolBaseListener {
    BufferedTokenStream tokens;
    TokenStreamRewriter rewriter;
        /** Create TokenStreamRewriter attached to token stream
         * sitting between the Cymbol lexer and parser.
         */
    public CommentShifter(BufferedTokenStream tokens) {
        this.tokens = tokens;
        rewriter = new TokenStreamRewriter(tokens);
    }

    @Override
    public void exitVarDecl(CymbolParser.VarDeclContext ctx) {
        Token semi = ctx.getStop();
        int i = semi.getTokenIndex();
        List<Token> cmtChannel =
                tokens.getHiddenTokensToRight(i, CymbolLexer.COMMENTS);
        if ( cmtChannel!=null ) {
            Token cmt = cmtChannel.get(0);
            if ( cmt!=null ) {
                String txt = cmt.getText().substring(2);
                String newCmt = "/* " + txt.trim() + " */\n";
                rewriter.insertBefore(ctx.start, newCmt);
                rewriter.replace(cmt, "\n");
            }

        }
    }
}

### lexmagic/ShiftVarComments.java

    CymbolLexer lexer = new CymbolLexer(input);
    CommonTokenStream tokens = new CommonTokenStream(lexer);
    CymbolParser parser = new CymbolParser(tokens);
    RuleContext tree = parser.file();
    ParseTreeWalker walker = new ParseTreeWalker();
➤   CommentShifter shifter = new CommentShifter(tokens);
➤   walker.walk(shifter, tree);
➤   System.out.print(shifter.rewriter.getText());


pg 219 (232)

12.3 Islands in the Stream     (Island Languages) // How to deal with preprocessor stuff


pg 253 (264)

Grammar Reference


## Dec 07, 2019

lexer commands look cool (pg 281<292>)


grun (parse tree display program for ANTLR4) only works on grammars with Java
    as the target language, so I can't print out/see the tokens/parse tree of
    CSharp files I run through the Python versions of the CSharp Lexer/Parsers.
    - Had to use Java version of CSharp Lexer/Parsers.
        -This means any modifications I make to the CSharp Lexer and Parser must
        be made on both Python and Java versions.   

In CSharpLexer, the '#' (SHARP) token to start a preprocessor directive changes 
    mode to DIRECTIVE mode, but is kept on DEFAULT channel (where as all rules 
    in DIRECTIVE mode are on the DIRECTIVE channel). 
    - This causes an error when using the CSharpParser as there are no rules
    for a standalone SHARP token.
    - As currently implemented, I cannot put SHARP in the DIRECTIVE channel as 
    the CSharpPreprocessorParser doesn't include SHARP in any of its rules.
    - Decided to put SHARP on the HIDDEN channel, which up until now was only 
    used for all WHITESPACE tokens.
        - May change this to a different channel later.
        - Could add rule to include SHARP in CSharpPreprocessor.
    - Changed my mind.
        - SHARP now gets added to DIRECTIVE channel
        - Added new rule to CSharpPreprocessorParser.
            - New rule takes name of previous starting rule 
            (preprocessor_directive).
            preprocessor_directive: 
                SHARP preprocessor_directive_inner (DIRECTIVE_NEW_LINE | EOF)
            
            - rename old 'preprocessor_directive' to 
            'preprocessor_directive_inner'
            - Since every alternative in 'preprocessor_directive_inner' ended 
            with '(DIRECTIVE_NEW_LINE | EOF)', moved 
            '(DIRECTIVE_NEW_LINE | EOF)' to 'preprocessor_directive'.


## Dec 22, 2019

Found that ANTLR target language templates uses a program/framework called
    StringTemplate4.
    - I've decided to use StringTemplate to handle the template handling 
    instead of creating my own controller and template languages.
    - StringTemplate puts template code in string template files (.st) and 
    string template group files (.stg), and controls/drives the templates using
    controller code in a target language (Java, C#, Objective-C).
        - Since Python is not an option for String template, I'm considering 
        using C# as the target language for both ANTLR4 and StringTemplate4.
        - Since StringTemplate will handle the text layout, a language like
        Python with that makes string manipulation easy won't be necessary.
    - .stg files allow importing other .st/.stg files and overriding named
    template blocks.

I will still need a way for the user to dictate what files get generated and 
    what templates get used.
    - Option 1: Create own language/API for user to invoke specific commands.
    - Option 2: User will have to write own controller code in target language
    that imports and uses StringTemplate4 framework.
    
    *** Chose option 3 ***
    - Option 3: Create own framework/API to run ANTLR code (to read in existing
    C# files and extract content) and to control StringTemplate code (create 
    instances of templates, pass data to templates, and write populated 
    templates to new files).
        - Create C# classes 
            - Write usage documentation for user to use framework.
            - Provide public methods that can be invoked by user.
            - Create Interfaces and/or Abstract classes for user classes to 
            inherit from, or I create concrete classes that inherit from
            Interfaces or Abstract classes that provide public methods for user
            to access.

## Dec 29, 2019

Remember to flush buffers regularly (when writing to a file)

pg 235 (247)        Chapter 13 Exploring the Runtime API

pg 238 (250)        13.3 Input Streams of Characters and Tokens

pg 239 (251)        13.4 Tokens and Token Factories

Pg 243 (255)        13.8 Unbuffered Character and Token Streams


## Dec 30, 2019

Create island language that embeds commands in C# comments.
    - Lex/parse with island language to break up C# code into chunks based on
    the embedded commands.
    - Lex/parse each chunk of C# code to take different actions based on the
    the embedded commands.


Figure out how to use Error Listeners.

Replace all literal (quoted) terminals in CSharpParser with their associated
    CSharpLexer rule identifiers.
    - When parser is compiled, each quoted terminal is converted to/treated like
    its equivalent lexer rule anyways.
    - Makes it easier for me to see what properties I need to call when trying
    to access the terminals of a rule in a listener/visitor.

Replace the rules LT='<', GT='>' with 
    OP_LT='<', OP_GT='>', OPEN_ANGLE='<', CLOSE_ANGLE='>'
    - Better portrays the semantic meaning of the usages (less_than/greater_than
    operators used individually without pair, while open/close angle brackets are
    always paired as they are brackets)
    - OP_LT and OP_GT match naming convention of other comparator operators.
    - OPEN_ANGLE and CLOSE_ANGLE match naming convention other bracket types.


## Jan 19, 2020

Using McMaster.Extensions.CommandLineUtils NuGet package (forked from 
Microsoft.Extensions.CommandLineUtils) to handle argument parsing.
    - Can require option argument values to match a value from a list or Enum
    - Can require option argument values to be of a specific type 
    (e.g. ExistingFileName)
    - Some or all arguments can be passed in a text file '@<filepath>' 
    (e.g. @Some/Path/ArgFile.txt)

D:\Files HDD\Workspace\csci491\Resources\TestData\Input\


## Feb 28

Services use case steps

//Check for Areas folder
//  If !exist:
//      Create Areas folder

//Check for <area> folder
//  If !exist:
//      Create <area> folder

//Check for Services folder
//  If !exist:
//      Create Services folder


//For each Service in Services:

//Check for <subFolders> folders:
//  Split <subFolder> path into folders (strings)
//  For each folder in <subFolder> path:
//      If !exist:
//          Create folder

//Check if <service> class file exists: 
//  If !exist:
//      Create <service> class file
//      Create serviceClass StringTemplate
//  Else:
//      Parse <service> class file
//          Extract list of existing public method signatures

//Check if <service> interface file exists
//  If !exist:
//      Create <service> interface file
//      Create serviceInterface StringTemplate
//  Else:
//      Parse <service> interface file
//          Extract list of existing method signatures

//Compare lists of method signatures between interface and class
//  If methods in class that are not in interface:
//      Create list of methods in class that are not in interface
//      Add missing methods to interface
//          Create StringTemplate for each method
//          Parse interface and use rewriter to insert methods into parse tree
//          Write parse tree as string to interface file
//  If methods in interface that aren't in class:
//      Create list of methods in interface that aren't in class
//      Add missing methods to class
//          Create StringTemplate for each method
//          Parse class and use rewriter to insert methods into parse tree
//          Write parse tree as string to class file

//Check if Startup.cs exists
//  If !exists:
//      Throw error
//  Else:
//      Parse Startup.cs
//          Find method "public void ConfigureServices(IServiceCollection services)"
//              Get name of IServiceCollection parameter (services)
//          Check each services.Add[Lifespan] method int the form
//                  If TypeParameters:  services.AddScoped(typeof(IMyService<>), typeof(MyService<>));
//                  Else:               services.AddScoped<IMyService, MyService>();
//              If found and Lifespan in services.Add[Lifespan] == Service.Lifespan:
//                  No action taken
//              Else if found and Lifespan in services.Add[Lifespan] != Service.Lifespan:
//                  Replace Add[Lifespan] with Add[Service.Lifespan] in token stream
//              Else:
//                  Create StringTemplate for services.Add[Lifespan] statement
//                      If TypeParameters:  services.AddScoped(typeof(IMyService<>), typeof(MyService<>));
//                      Else:               services.AddScoped<IMyService, MyService>();
//                  Use rewriter to insert services.Add[Lifespan] into token stream
//                  Write parse tree as string to Startup.cs

//Inject Service into Controllers
//  For each Controller in Service.Controllers:
//      Check whether [Controller.Name].cs exists:
//              If Controller.Area != null:
//                  ~/Areas/[Controller.Area]/Controllers/[Controller.Name].cs
//              Else:
//                  ~/Controllers/[Controller.Name].cs
//                  ~/Areas/[Service.Area]/Controllers/[Controller.Name].cs
//          If !exists:
//              Throw error
//          Else:
//              Parse Controller file and check whether service has been injected
//                  If injection exists:
//                      No action
//                  Else:
//                      Create StringTemplates for private variable:
//                          private IMyService _myService;
//                      If no contructor for Controller:
//                          Create StringTemplates for Controller with "IMyService myService" as a parameter 
//                                  and assign parameter to private variable:
//                              public MyController(IMyService myService)
//                              {
//                                  _myService = myService;
//                              }
//                      Else:
//                          Add "IMyService myService" as a parameter to the constructor
//                          Add line to assign parameter to private variable: "_myService = myService;"
//                      Use rewriter to insert services.Add[Lifespan] into token stream
//                      Write parse tree as string to Controller file
